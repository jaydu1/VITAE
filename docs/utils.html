<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>VITAE.utils API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_CHTML'></script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>VITAE.utils</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
import sys
import os
import random
import numpy as np
import pandas as pd
from numba import jit, float32, int32
import scipy
from scipy import stats

import tensorflow as tf
import tensorflow.keras as keras
from tensorflow.keras import backend as K

import h5py
import anndata

from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from umap.umap_ import nearest_neighbors, smooth_knn_dist
import umap
from scipy.sparse import coo_matrix
import igraph as ig
import leidenalg

import matplotlib.pyplot as plt
import matplotlib


#------------------------------------------------------------------------------
# Early stopping
#------------------------------------------------------------------------------

class Early_Stopping():
    &#39;&#39;&#39;
    The early-stopping monitor.
    &#39;&#39;&#39;
    def __init__(self, warmup=0, patience=10, tolerance=1e-3, 
            relative=False, is_minimize=True):
        self.warmup = warmup
        self.patience = patience
        self.tolerance = tolerance
        self.is_minimize = is_minimize
        self.relative = relative

        self.step = -1
        self.best_step = -1
        self.best_metric = np.inf

        if not self.is_minimize:
            self.factor = -1.0
        else:
            self.factor = 1.0

    def __call__(self, metric):
        self.step += 1
        
        if self.step &lt; self.warmup:
            return False
        elif (self.best_metric==np.inf) or \
                (self.relative and (self.best_metric-metric)/self.best_metric &gt; self.tolerance) or \
                ((not self.relative) and self.factor*metric&lt;self.factor*self.best_metric-self.tolerance):
            self.best_metric = metric
            self.best_step = self.step
            return False
        elif self.step - self.best_step&gt;self.patience:
            print(&#39;Best Epoch: %d. Best Metric: %f.&#39;%(self.best_step, self.best_metric))
            return True
        else:
            return False
            
            
#------------------------------------------------------------------------------
# Utils functions
#------------------------------------------------------------------------------

def reset_random_seeds(seed):
    os.environ[&#39;PYTHONHASHSEED&#39;]=str(seed)
    tf.keras.backend.clear_session()
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)


def _comp_dist(x, y, mu=None, S=None):
    uni_y = np.unique(y)
    n_uni_y = len(uni_y)
    d = x.shape[1]
    if mu is None:
        mu = np.zeros((n_uni_y, d))
        for i,l in enumerate(uni_y):
            mu[i, :] = np.mean(x[y==l], axis=0)
    if S is None:
        S = np.zeros((n_uni_y, d, d))
        for i,l in enumerate(uni_y):
            S[i, :, :] = np.cov(x[y==l], rowvar=False)
    dist = np.zeros((n_uni_y, n_uni_y))
    for i,li in enumerate(uni_y):
        for j,lj in enumerate(uni_y):            
            if i&lt;j:
                dist[i,j] = (mu[i:i+1,:]-mu[j:j+1,:]) @ np.linalg.inv(S[i, :, :] + S[j, :, :]) @ (mu[i:i+1,:]-mu[j:j+1,:]).T
    dist = dist + dist.T
    return dist


def get_embedding(z, dimred=&#39;umap&#39;, **kwargs):
    &#39;&#39;&#39;Get low-dimensional embeddings for visualizations.

    Parameters
    ----------
    z : np.array
        \([N, d]\) The latent variables.
    dimred : str, optional
        &#39;pca&#39;, &#39;tsne&#39;, or umap&#39;.   
    **kwargs :  
        Extra key-value arguments for dimension reduction algorithms.  

    Returns:
    ----------
    embed : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    &#39;&#39;&#39;
    if dimred==&#39;umap&#39;:
        if &#39;random_state&#39; in kwargs:
            kwargs[&#39;random_state&#39;] = np.random.RandomState(kwargs[&#39;random_state&#39;])
        # umap has some bugs that it may change the original matrix when doing transform 
        mapper = umap.UMAP(**kwargs).fit(z.copy())
        embed = mapper.embedding_
    elif dimred==&#39;pca&#39;:
        kwargs[&#39;n_components&#39;] = 2            
        embed = PCA(**kwargs).fit_transform(z)
    elif dimred==&#39;tsne&#39;:
        embed = TSNE(**kwargs).fit_transform(z)
    else:
        raise ValueError(&#34;Dimension reduction method can only be &#39;umap&#39;, &#39;pca&#39; or &#39;tsne&#39;!&#34;)
    return embed


def _compute_membership_strengths(knn_indices, knn_dists, sigmas, rhos, return_dists=False, bipartite=False):
    &#39;&#39;&#39;
    Overwrite the UMAP `compute_membership_strengths` function to allow computation with float64.
    &#39;&#39;&#39;
    n_samples = knn_indices.shape[0]
    n_neighbors = knn_indices.shape[1]

    rows = np.zeros(knn_indices.size, dtype=np.int32)
    cols = np.zeros(knn_indices.size, dtype=np.int32)
    vals = np.zeros(knn_indices.size, dtype=np.float64)
    if return_dists:
        dists = np.zeros(knn_indices.size, dtype=np.float64)
    else:
        dists = None

    for i in range(n_samples):
        for j in range(n_neighbors):
            if knn_indices[i, j] == -1:
                continue  # We didn&#39;t get the full knn for i
            # If applied to an adjacency matrix points shouldn&#39;t be similar to themselves.
            # If applied to an incidence matrix (or bipartite) then the row and column indices are different.
            if (bipartite == False) &amp; (knn_indices[i, j] == i):
                val = 0.0
            elif knn_dists[i, j] - rhos[i] &lt;= 0.0 or sigmas[i] == 0.0:
                val = 1.0
            else:
                val = np.exp(-((knn_dists[i, j] - rhos[i]) / (sigmas[i])))

            rows[i * n_neighbors + j] = i
            cols[i * n_neighbors + j] = knn_indices[i, j]
            vals[i * n_neighbors + j] = val
            if return_dists:
                dists[i * n_neighbors + j] = knn_dists[i, j]

    return rows, cols, vals, dists


def _fuzzy_simplicial_set(X, n_neighbors, random_state,
    metric, metric_kwds={}, knn_indices=None, knn_dists=None, angular=False,
    set_op_mix_ratio=1.0, local_connectivity=1.0, apply_set_operations=True,
    verbose=False, return_dists=None):
    &#39;&#39;&#39;
    Overwrite the UMAP `fuzzy_simplicial_set` function to allow computation with float64.
    &#39;&#39;&#39;

    if knn_indices is None or knn_dists is None:
        knn_indices, knn_dists, _ = nearest_neighbors(
            X, n_neighbors, metric, metric_kwds, angular, random_state, verbose=verbose,
        )

    sigmas, rhos = smooth_knn_dist(
        knn_dists, float(n_neighbors), local_connectivity=float(local_connectivity),
    )

    rows, cols, vals, dists = _compute_membership_strengths(
        knn_indices, knn_dists, sigmas, rhos, return_dists
    )

    result = scipy.sparse.coo_matrix(
        (vals, (rows, cols)), shape=(X.shape[0], X.shape[0])
    )
    result.eliminate_zeros()

    if apply_set_operations:
        transpose = result.transpose()

        prod_matrix = result.multiply(transpose)

        result = (
            set_op_mix_ratio * (result + transpose - prod_matrix)
            + (1.0 - set_op_mix_ratio) * prod_matrix
        )

    result.eliminate_zeros()

    if return_dists is None:
        return result, sigmas, rhos
    else:
        if return_dists:
            dmat = scipy.sparse.coo_matrix(
                (dists, (rows, cols)), shape=(X.shape[0], X.shape[0])
            )

            dists = dmat.maximum(dmat.transpose()).todok()
        else:
            dists = None

        return result, sigmas, rhos, dists


def get_igraph(z, random_state=0):
    &#39;&#39;&#39;Get igraph for running Leidenalg clustering.

    Parameters
    ----------
    z : np.array
        \([N, d]\) The latent variables.
    random_state : int, optional
        The random state.
    Returns:
    ----------
    g : igraph
        The igraph object of connectivities.      
    &#39;&#39;&#39;    
    # Find knn
    n_neighbors = 15
    knn_indices, knn_dists, forest = nearest_neighbors(
        z, n_neighbors, 
        random_state=np.random.RandomState(random_state),
        metric=&#39;euclidean&#39;, metric_kwds={},
        angular=False, verbose=False,
    )

    # Build graph
    n_obs = z.shape[0]
    X = coo_matrix(([], ([], [])), shape=(n_obs, 1))
    connectivities = _fuzzy_simplicial_set(
        X,
        n_neighbors,
        random_state=np.random.RandomState(random_state),
        metric=None,
        knn_indices=knn_indices,
        knn_dists=knn_dists,
        set_op_mix_ratio=1.0,
        local_connectivity=1.0,
    )[0].tocsr()

    # Get igraph graph from adjacency matrix
    sources, targets = connectivities.nonzero()
    weights = connectivities[sources, targets].A1
    g = ig.Graph(directed=None)
    g.add_vertices(connectivities.shape[0])
    g.add_edges(list(zip(sources, targets)))
    g.es[&#39;weight&#39;] = weights
    return g


def leidenalg_igraph(g, res, random_state=0):
    &#39;&#39;&#39;Leidenalg clustering on an igraph object.

    Parameters
    ----------
    g : igraph
        The igraph object of connectivities.
    res : float
        The resolution parameter for Leidenalg clustering.
    random_state : int, optional
        The random state.      

    Returns
    ----------
    labels : np.array     
        \([N, ]\) The clustered labels.
    &#39;&#39;&#39;
    partition_kwargs = {}
    partition_type = leidenalg.RBConfigurationVertexPartition
    partition_kwargs[&#34;resolution_parameter&#34;] = res
    partition_kwargs[&#34;seed&#34;] = random_state
    part = leidenalg.find_partition(
                    g, partition_type,
                    **partition_kwargs,
                )
    labels = np.array(part.membership)
    return labels
    

def plot_clusters(embed_z, labels, plot_labels=False, path=None):
    &#39;&#39;&#39;Plot the clustering results.

    Parameters
    ----------
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    labels : np.array     
        \([N, ]\) The clustered labels.
    plot_labels : boolean, optional
        Whether to plot text of labels or not.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;    
    n_labels = len(np.unique(labels))
    colors = [plt.cm.jet(float(i)/n_labels) for i in range(n_labels)]
    
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    for i,l in enumerate(np.unique(labels)):
        ax.scatter(*embed_z[labels==l].T,
                    c=[colors[i]], label=str(l),
                    s=16, alpha=0.4)
        if plot_labels:
            ax.text(np.mean(embed_z[labels==l,0]), np.mean(embed_z[labels==l,1]), str(l), fontsize=16)
    plt.setp(ax, xticks=[], yticks=[])
    box = ax.get_position()
    ax.set_position([box.x0, box.y0 + box.height * 0.1,
                        box.width, box.height * 0.9])
    ax.legend(loc=&#39;upper center&#39;, bbox_to_anchor=(0.5, -0.05),
        fancybox=True, shadow=True, markerscale=3, ncol=5)
    ax.set_title(&#39;Clustering&#39;)
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.plot()

    
def plot_marker_gene(expression, gene_name: str, embed_z, path=None):
    &#39;&#39;&#39;Plot the marker gene.

    Parameters
    ----------
    expression : np.array
        \([N, ]\) The expression of the marker gene.
    gene_name : str
        The name of the marker gene.
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;      
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    cmap = matplotlib.cm.get_cmap(&#39;Reds&#39;)
    sc = ax.scatter(*embed_z.T, c=&#39;yellow&#39;, s=15, alpha=0.1)
    sc = ax.scatter(*embed_z.T, cmap=cmap, c=expression, s=10, alpha=0.5)
    plt.colorbar(sc, ax=[ax], location=&#39;right&#39;)
    plt.setp(ax, xticks=[], yticks=[])
    ax.set_title(&#39;Normalized expression of {}&#39;.format(gene_name))
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.show()
    return None


def plot_uncertainty(uncertainty, embed_z, path=None):
    &#39;&#39;&#39;Plot the uncertainty for all selected cells.

    Parameters
    ----------
    uncertainty : np.array
        \([N, ]\) The uncertainty of the all cells.    
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;          
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    cmap = matplotlib.cm.get_cmap(&#39;RdBu_r&#39;)
    sc = ax.scatter(*embed_z.T, cmap=cmap, c=uncertainty, s=10, alpha=1.0)
    plt.colorbar(sc, ax=[ax], location=&#39;right&#39;)
    plt.setp(ax, xticks=[], yticks=[])
    ax.set_title(&#34;Cells&#39; Uncertainty&#34;)
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.show()
    return None


def _polyfit_with_fixed_points(n, x, y, xf, yf):
    &#39;&#39;&#39;
    Fix a polynomial with degree n that goes through 
    fixed points (xf_j, yf_j).
    &#39;&#39;&#39;
    mat = np.empty((n + 1 + len(xf),) * 2)
    vec = np.empty((n + 1 + len(xf),))
    x_n = x**np.arange(2 * n + 1)[:, None]
    yx_n = np.sum(x_n[:n + 1] * y, axis=1)
    x_n = np.sum(x_n, axis=1)
    idx = np.arange(n + 1) + np.arange(n + 1)[:, None]
    mat[:n + 1, :n + 1] = np.take(x_n, idx)
    xf_n = xf**np.arange(n + 1)[:, None]
    mat[:n + 1, n + 1:] = xf_n / 2
    mat[n + 1:, :n + 1] = xf_n.T
    mat[n + 1:, n + 1:] = 0
    vec[:n + 1] = yx_n
    vec[n + 1:] = yf
    params = np.linalg.solve(mat, vec)

    return params[:n + 1]


def _get_smooth_curve(xy, xy_fixed, y_range):
    xy = np.r_[xy, xy_fixed]
    _, idx = np.unique(xy[:,0], return_index=True)
    xy = xy[idx,:]
    order = 3
    while order&gt;0:
        params = _polyfit_with_fixed_points(
            order, 
            xy[:,0], xy[:,1], 
            xy_fixed[:,0], xy_fixed[:,1]
            )
        poly = np.polynomial.Polynomial(params)
        xx = np.linspace(xy_fixed[0,0], xy_fixed[-1,0], 100)
        yy = poly(xx)
        if np.max(yy)&gt;y_range[1] or np.min(yy)&lt;y_range[0] :
            order -= 1
        else:
            break
    return xx, yy


def _pinv_extended(x, rcond=1e-15):
    &#34;&#34;&#34;
    Return the pinv of an array X as well as the singular values
    used in computation.
    Code adapted from numpy.
    &#34;&#34;&#34;
    x = np.asarray(x)
    x = x.conjugate()
    u, s, vt = np.linalg.svd(x, False)
    s_orig = np.copy(s)
    m = u.shape[0]
    n = vt.shape[1]
    cutoff = rcond * np.maximum.reduce(s)
    for i in range(min(n, m)):
        if s[i] &gt; cutoff:
            s[i] = 1./s[i]
        else:
            s[i] = 0.
    res = np.dot(np.transpose(vt), np.multiply(s[:, np.core.newaxis],
                                               np.transpose(u)))
    return res, s_orig


def _cov_hc3(h, pinv_wexog, resid):
    het_scale = (resid/(1-h))**2

    # sandwich with pinv(x) * diag(scale) * pinv(x).T
    # where pinv(x) = (X&#39;X)^(-1) X and scale is (nobs,)
    cov_hc3_ = np.dot(pinv_wexog, het_scale[:,None]*pinv_wexog.T)
    return cov_hc3_


def _p_adjust_bh(p):
    &#34;&#34;&#34;Benjamini-Hochberg p-value correction for multiple hypothesis testing.&#34;&#34;&#34;
    n = len(p)
    nna = ~np.isnan(p)
    lp = np.sum(nna)

    p0 = np.empty_like(p)
    p0[~nna] = np.nan
    p = p[nna]
    by_descend = p.argsort()[::-1]
    by_orig = by_descend.argsort()
    steps = float(lp) / np.arange(lp, 0, -1)
    p0[nna] = np.minimum(1, np.minimum.accumulate(steps * p[by_descend]))[by_orig]
    return p0

def DE_test(Y, X, gene_names, i_test, alpha: float = 0.05):
    &#39;&#39;&#39;Differential gene expression test.

    Parameters
    ----------
    Y : numpy.array
        \(n,\) the expression matrix.
    X : numpy.array
        \(n,1+1+s\) the constant term, the pseudotime and the covariates.
    gene_names : numpy.array
        \(n,\) the names of all genes.
    i_test : numpy.array
        The indices of covariates to be tested.
    alpha : float, optional
        The cutoff of p-values.

    Returns
    ----------
    res_df : pandas.DataFrame
        The test results of expressed genes with two columns,
        the estimated coefficients and the adjusted p-values.
    &#39;&#39;&#39;
    pinv_wexog, singular_values = _pinv_extended(X)
    normalized_cov = np.dot(
            pinv_wexog, np.transpose(pinv_wexog))
    h = np.diag(np.dot(X,
                    np.dot(normalized_cov,X.T)))

    def _DE_test(wendog,pinv_wexog,h):
        if np.any(np.isnan(wendog)):
            return np.empty(2)*np.nan
        else:
            beta = np.dot(pinv_wexog, wendog)
            resid = wendog - X @ beta
            cov = _cov_hc3(h, pinv_wexog, resid)
            t = np.array([])
            for j in i_test:
                if np.diag(cov)[j] == 0:
                    _t = float(&#34;nan&#34;)
                else:
                    _t = beta[j]/(np.sqrt(np.diag(cov)[j])+1e-6)
                t = np.append(t, _t)
            return np.r_[beta[i_test], t]

    res = np.apply_along_axis(lambda y: _DE_test(wendog=y, pinv_wexog=pinv_wexog, h=h),
                            0,
                            Y).T

    res_df = pd.DataFrame()
    for i,j in enumerate(i_test):
        if &#39;median_abs_deviation&#39; in dir(stats):
            sigma = stats.median_abs_deviation(res[:,len(i_test)+i], nan_policy=&#39;omit&#39;)
        else:
            sigma = stats.median_absolute_deviation(res[:,len(i_test)+i], nan_policy=&#39;omit&#39;)
        pdt_new_pval = np.array([stats.norm.sf(x)*2 for x in np.abs(res[:,len(i_test)+i]/sigma)])
        new_adj_pval = _p_adjust_bh(pdt_new_pval/len(i_test))
        _res_df = pd.DataFrame(np.c_[res[:,i], pdt_new_pval, new_adj_pval],
                        index=gene_names,
                        columns=[&#39;beta_{}&#39;.format(j),
                                 &#39;pvalue_{}&#39;.format(j),
                                 &#39;pvalue_adjusted_{}&#39;.format(j)])
        res_df = pd.concat([res_df, _res_df], axis=1)
    res_df = res_df[
        (np.sum(
            res_df[
                res_df.columns[
                    np.char.startswith(
                        np.array(res_df.columns, dtype=str),
                        &#39;pvalue_adjusted&#39;)]
            ] &lt; alpha, axis=1
        )&gt;0) &amp; np.any(~np.isnan(Y), axis=0)]
#     res_df = res_df.iloc[np.argsort(res_df.pvalue_adjusted).tolist(), :]
    return res_df


#------------------------------------------------------------------------------
# Data loader
#------------------------------------------------------------------------------

type_dict = {
    # real data / dyno
    &#39;dentate_withdays&#39;:&#39;UMI&#39;,
    &#39;dentate&#39;:&#39;UMI&#39;, 
    &#39;immune&#39;:&#39;UMI&#39;, 
    &#39;neonatal&#39;:&#39;UMI&#39;, 
    &#39;mouse_brain&#39;:&#39;UMI&#39;, 
    &#39;mouse_brain_miller&#39;:&#39;UMI&#39;,
    &#39;mouse_brain_merged&#39;:&#39;UMI&#39;,
    &#39;planaria_full&#39;:&#39;UMI&#39;, 
    &#39;planaria_muscle&#39;:&#39;UMI&#39;,
    &#39;aging&#39;:&#39;non-UMI&#39;, 
    &#39;cell_cycle&#39;:&#39;non-UMI&#39;,
    &#39;fibroblast&#39;:&#39;non-UMI&#39;, 
    &#39;germline&#39;:&#39;non-UMI&#39;,    
    &#39;human_embryos&#39;:&#39;non-UMI&#39;, 
    &#39;mesoderm&#39;:&#39;non-UMI&#39;,
    &#39;human_hematopoiesis_scATAC&#39;:&#39;UMI&#39;,
    &#39;human_hematopoiesis_scRNA&#39;:&#39;UMI&#39;,
    
    # dyngen
    &#34;linear_1&#34;:&#39;non-UMI&#39;, 
    &#34;linear_2&#34;:&#39;non-UMI&#39;, 
    &#34;linear_3&#34;:&#39;non-UMI&#39;,
    &#39;bifurcating_1&#39;:&#39;non-UMI&#39;,
    &#39;bifurcating_2&#39;:&#39;non-UMI&#39;,
    &#34;bifurcating_3&#34;:&#39;non-UMI&#39;, 
    &#34;cycle_1&#34;:&#39;non-UMI&#39;, 
    &#34;cycle_2&#34;:&#39;non-UMI&#39;, 
    &#34;cycle_3&#34;:&#39;non-UMI&#39;,
    &#34;trifurcating_1&#34;:&#39;non-UMI&#39;, 
    &#34;trifurcating_2&#34;:&#39;non-UMI&#39;,         
    &#34;converging_1&#34;:&#39;non-UMI&#39;,
    
    # our model
    &#39;linear&#39;:&#39;UMI&#39;,
    &#39;bifurcation&#39;:&#39;UMI&#39;,
    &#39;multifurcating&#39;:&#39;UMI&#39;,
    &#39;tree&#39;:&#39;UMI&#39;,
}




def load_data(path, file_name,return_dict = False):
    &#39;&#39;&#39;Load h5df data.

    Parameters
    ----------
    path : str
        The path of the h5 files.
    file_name : str
        The dataset name.
    
    Returns:
    ----------
    data : dict
        The dict containing count, grouping, etc. of the dataset.
    &#39;&#39;&#39;     
    data = {}
    
    with h5py.File(os.path.join(path, file_name+&#39;.h5&#39;), &#39;r&#39;) as f:
        data[&#39;count&#39;] = np.array(f[&#39;count&#39;], dtype=np.float32)
        dd = anndata.AnnData(X=data[&#34;count&#34;])
        dd.layers[&#34;count&#34;] = data[&#34;count&#34;].copy()

        data[&#39;grouping&#39;] = np.array(f[&#39;grouping&#39;]).astype(str)
        dd.obs[&#34;grouping&#34;] = data[&#34;grouping&#34;]
        dd.obs[&#34;grouping&#34;] = dd.obs[&#34;grouping&#34;].astype(&#34;category&#34;)
        if &#39;gene_names&#39; in f:
            data[&#39;gene_names&#39;] = np.array(f[&#39;gene_names&#39;]).astype(str)
            dd.var.index = data[&#34;gene_names&#34;]
        else:
            data[&#39;gene_names&#39;] = None
        if &#39;cell_ids&#39; in f:
            data[&#39;cell_ids&#39;] = np.array(f[&#39;cell_ids&#39;]).astype(str)
            dd.obs.index = data[&#34;cell_ids&#34;]
        else:
            data[&#39;cell_ids&#39;] = None
        if &#39;days&#39; in f:
            data[&#39;days&#39;] = np.array(f[&#39;days&#39;]).astype(str)

        if &#39;milestone_network&#39; in f:
            if file_name in [&#39;linear&#39;,&#39;bifurcation&#39;,&#39;multifurcating&#39;,&#39;tree&#39;,
                               &#34;cycle_1&#34;, &#34;cycle_2&#34;, &#34;cycle_3&#34;,
                            &#34;linear_1&#34;, &#34;linear_2&#34;, &#34;linear_3&#34;, 
                            &#34;trifurcating_1&#34;, &#34;trifurcating_2&#34;, 
                            &#34;bifurcating_1&#34;, &#39;bifurcating_2&#39;, &#34;bifurcating_3&#34;, 
                            &#34;converging_1&#34;]:
                data[&#39;milestone_network&#39;] = pd.DataFrame(
                    np.array(np.array(list(f[&#39;milestone_network&#39;])).tolist(), dtype=str), 
                    columns=[&#39;from&#39;,&#39;to&#39;,&#39;w&#39;]
                ).astype({&#39;w&#39;:np.float32})
            else:
                data[&#39;milestone_network&#39;] = pd.DataFrame(
                    np.array(np.array(list(f[&#39;milestone_network&#39;])).tolist(), dtype=str), 
                    columns=[&#39;from&#39;,&#39;to&#39;]
                )
            data[&#39;root_milestone_id&#39;] = np.array(f[&#39;root_milestone_id&#39;]).astype(str)[0]            
        else:
            data[&#39;milestone_net&#39;] = None
            data[&#39;root_milestone_id&#39;] = None
            
        if file_name in [&#39;mouse_brain&#39;, &#39;mouse_brain_miller&#39;]:
            data[&#39;grouping&#39;] = np.array([&#39;%02d&#39;%int(i) for i in data[&#39;grouping&#39;]], dtype=object)
            data[&#39;root_milestone_id&#39;] = dict(zip([&#39;mouse_brain&#39;, &#39;mouse_brain_miller&#39;], [&#39;06&#39;, &#39;05&#39;]))[file_name]
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])).tolist(), dtype=np.float32)
        if file_name in [&#39;mouse_brain_merged&#39;]:
            data[&#39;grouping&#39;] = np.array(data[&#39;grouping&#39;], dtype=object)
            data[&#39;root_milestone_id&#39;] = np.array(f[&#39;root_milestone_id&#39;]).astype(str)[0]
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])).tolist(), dtype=np.float32)
        if file_name == &#39;dentate_withdays&#39;:
            data[&#39;covariates&#39;] = np.array([item.decode(&#39;utf-8&#39;).replace(&#39;*&#39;, &#39;&#39;) for item in f[&#39;days&#39;]], dtype=object)
            data[&#39;covariates&#39;] = data[&#39;covariates&#39;].astype(float).reshape(-1, 1)
        if file_name.startswith(&#39;human_hematopoiesis&#39;):
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])[0], dtype=str).tolist()).reshape((-1,1))
            
    data[&#39;type&#39;] = type_dict[file_name]
    if data[&#39;type&#39;]==&#39;non-UMI&#39;:
        scale_factor = np.sum(data[&#39;count&#39;],axis=1, keepdims=True)/1e6
        data[&#39;count&#39;] = data[&#39;count&#39;]/scale_factor

    if data.get(&#34;covariates&#34;) is not None:
        cov = data.get(&#34;covariates&#34;)
        cov_name = [&#34;covariate_&#34; + str(i) for i in range(cov.shape[1])]
        dd.obs[cov_name] = cov

    if return_dict:
        return data,dd
    else:
        return dd


# Below are some functions used in calculating MMD loss

def compute_kernel(x, y, kernel=&#39;rbf&#39;, **kwargs):
    &#34;&#34;&#34;Computes RBF kernel between x and y.

    Parameters
    ----------
        x: Tensor
            Tensor with shape [batch_size, z_dim]
        y: Tensor
            Tensor with shape [batch_size, z_dim]

    Returns
    ----------
        The computed RBF kernel between x and y
    &#34;&#34;&#34;
    scales = kwargs.get(&#34;scales&#34;, [])
    if kernel == &#34;rbf&#34;:
        x_size = K.shape(x)[0]
        y_size = K.shape(y)[0]
        dim = K.shape(x)[1]
        tiled_x = K.tile(K.reshape(x, K.stack([x_size, 1, dim])), K.stack([1, y_size, 1]))
        tiled_y = K.tile(K.reshape(y, K.stack([1, y_size, dim])), K.stack([x_size, 1, 1]))
        return K.exp(-K.mean(K.square(tiled_x - tiled_y), axis=2) / K.cast(dim, tf.float32))
    elif kernel == &#39;raphy&#39;:
        scales = K.variable(value=np.asarray(scales))
        squared_dist = K.expand_dims(squared_distance(x, y), 0)
        scales = K.expand_dims(K.expand_dims(scales, -1), -1)
        weights = K.eval(K.shape(scales)[0])
        weights = K.variable(value=np.asarray(weights))
        weights = K.expand_dims(K.expand_dims(weights, -1), -1)
        return K.sum(weights * K.exp(-squared_dist / (K.pow(scales, 2))), 0)
    elif kernel == &#34;multi-scale-rbf&#34;:
        sigmas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100, 1e3, 1e4, 1e5, 1e6]

        beta = 1. / (2. * (K.expand_dims(sigmas, 1)))
        distances = squared_distance(x, y)
        s = K.dot(beta, K.reshape(distances, (1, -1)))

        return K.reshape(tf.reduce_sum(input_tensor=tf.exp(-s), axis=0), K.shape(distances)) / len(sigmas)


def squared_distance(x, y):
    &#39;&#39;&#39;Compute the pairwise euclidean distance.

    Parameters
    ----------
    x: Tensor
        Tensor with shape [batch_size, z_dim]
    y: Tensor
        Tensor with shape [batch_size, z_dim]

    Returns
    ----------
    The pairwise euclidean distance between x and y.
    &#39;&#39;&#39;
    r = K.expand_dims(x, axis=1)
    return K.sum(K.square(r - y), axis=-1)


def compute_mmd(x, y, kernel, **kwargs):
    &#34;&#34;&#34;Computes Maximum Mean Discrepancy(MMD) between x and y.
    
    Parameters
    ----------
    x: Tensor
        Tensor with shape [batch_size, z_dim]
    y: Tensor
        Tensor with shape [batch_size, z_dim]
    kernel: str
        The kernel type used in MMD. It can be &#39;rbf&#39;, &#39;multi-scale-rbf&#39; or &#39;raphy&#39;.
    **kwargs: dict
        The parameters used in kernel function.
    
    Returns
    ----------
    The computed MMD between x and y
    &#34;&#34;&#34;
    x_kernel = compute_kernel(x, x, kernel=kernel, **kwargs)
    y_kernel = compute_kernel(y, y, kernel=kernel, **kwargs)
    xy_kernel = compute_kernel(x, y, kernel=kernel, **kwargs)
    return K.mean(x_kernel) + K.mean(y_kernel) - 2 * K.mean(xy_kernel)


def sample_z(args):
    &#34;&#34;&#34;Samples from standard Normal distribution with shape [size, z_dim] and
    applies re-parametrization trick. It is actually sampling from latent
    space distributions with N(mu, var) computed in `_encoder` function.
    
    Parameters
    ----------
    args: list
        List of [mu, log_var] computed in `_encoder` function.
        
    Returns
    ----------
    The computed Tensor of samples with shape [size, z_dim].
    &#34;&#34;&#34;
    mu, log_var = args
    batch_size = K.shape(mu)[0]
    z_dim = K.int_shape(mu)[1]
    eps = K.random_normal(shape=[batch_size, z_dim])
    return mu + K.exp(log_var / 2) * eps


def _nan2zero(x):
    return tf.where(tf.math.is_nan(x), tf.zeros_like(x), x)


def _nan2inf(x):
    return tf.where(tf.math.is_nan(x), tf.zeros_like(x) + np.inf, x)

def _nelem(x):
    nelem = tf.reduce_sum(input_tensor=tf.cast(~tf.math.is_nan(x), tf.float32))
    return tf.cast(tf.compat.v1.where(tf.equal(nelem, 0.), 1., nelem), x.dtype)


def _reduce_mean(x):
    nelem = _nelem(x)
    x = _nan2zero(x)
    return tf.divide(tf.reduce_sum(input_tensor=x), nelem)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="VITAE.utils.reset_random_seeds"><code class="name flex">
<span>def <span class="ident">reset_random_seeds</span></span>(<span>seed)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_random_seeds(seed):
    os.environ[&#39;PYTHONHASHSEED&#39;]=str(seed)
    tf.keras.backend.clear_session()
    random.seed(seed)
    np.random.seed(seed)
    tf.random.set_seed(seed)</code></pre>
</details>
</dd>
<dt id="VITAE.utils.get_embedding"><code class="name flex">
<span>def <span class="ident">get_embedding</span></span>(<span>z, dimred='umap', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Get low-dimensional embeddings for visualizations.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>z</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, d]</span><script type="math/tex">[N, d]</script></span> The latent variables.</dd>
<dt><strong><code>dimred</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>'pca', 'tsne', or umap'.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code> </code></dt>
<dd>Extra key-value arguments for dimension reduction algorithms.</dd>
</dl>
<h2 id="returns">Returns:</h2>
<p>embed : np.array
<span><span class="MathJax_Preview">[N, 2]</span><script type="math/tex">[N, 2]</script></span> The latent variables after dimension reduction.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_embedding(z, dimred=&#39;umap&#39;, **kwargs):
    &#39;&#39;&#39;Get low-dimensional embeddings for visualizations.

    Parameters
    ----------
    z : np.array
        \([N, d]\) The latent variables.
    dimred : str, optional
        &#39;pca&#39;, &#39;tsne&#39;, or umap&#39;.   
    **kwargs :  
        Extra key-value arguments for dimension reduction algorithms.  

    Returns:
    ----------
    embed : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    &#39;&#39;&#39;
    if dimred==&#39;umap&#39;:
        if &#39;random_state&#39; in kwargs:
            kwargs[&#39;random_state&#39;] = np.random.RandomState(kwargs[&#39;random_state&#39;])
        # umap has some bugs that it may change the original matrix when doing transform 
        mapper = umap.UMAP(**kwargs).fit(z.copy())
        embed = mapper.embedding_
    elif dimred==&#39;pca&#39;:
        kwargs[&#39;n_components&#39;] = 2            
        embed = PCA(**kwargs).fit_transform(z)
    elif dimred==&#39;tsne&#39;:
        embed = TSNE(**kwargs).fit_transform(z)
    else:
        raise ValueError(&#34;Dimension reduction method can only be &#39;umap&#39;, &#39;pca&#39; or &#39;tsne&#39;!&#34;)
    return embed</code></pre>
</details>
</dd>
<dt id="VITAE.utils.get_igraph"><code class="name flex">
<span>def <span class="ident">get_igraph</span></span>(<span>z, random_state=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Get igraph for running Leidenalg clustering.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>z</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, d]</span><script type="math/tex">[N, d]</script></span> The latent variables.</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The random state.</dd>
</dl>
<h2 id="returns">Returns:</h2>
<p>g : igraph
The igraph object of connectivities.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_igraph(z, random_state=0):
    &#39;&#39;&#39;Get igraph for running Leidenalg clustering.

    Parameters
    ----------
    z : np.array
        \([N, d]\) The latent variables.
    random_state : int, optional
        The random state.
    Returns:
    ----------
    g : igraph
        The igraph object of connectivities.      
    &#39;&#39;&#39;    
    # Find knn
    n_neighbors = 15
    knn_indices, knn_dists, forest = nearest_neighbors(
        z, n_neighbors, 
        random_state=np.random.RandomState(random_state),
        metric=&#39;euclidean&#39;, metric_kwds={},
        angular=False, verbose=False,
    )

    # Build graph
    n_obs = z.shape[0]
    X = coo_matrix(([], ([], [])), shape=(n_obs, 1))
    connectivities = _fuzzy_simplicial_set(
        X,
        n_neighbors,
        random_state=np.random.RandomState(random_state),
        metric=None,
        knn_indices=knn_indices,
        knn_dists=knn_dists,
        set_op_mix_ratio=1.0,
        local_connectivity=1.0,
    )[0].tocsr()

    # Get igraph graph from adjacency matrix
    sources, targets = connectivities.nonzero()
    weights = connectivities[sources, targets].A1
    g = ig.Graph(directed=None)
    g.add_vertices(connectivities.shape[0])
    g.add_edges(list(zip(sources, targets)))
    g.es[&#39;weight&#39;] = weights
    return g</code></pre>
</details>
</dd>
<dt id="VITAE.utils.leidenalg_igraph"><code class="name flex">
<span>def <span class="ident">leidenalg_igraph</span></span>(<span>g, res, random_state=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Leidenalg clustering on an igraph object.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>g</code></strong> :&ensp;<code>igraph</code></dt>
<dd>The igraph object of connectivities.</dd>
<dt><strong><code>res</code></strong> :&ensp;<code>float</code></dt>
<dd>The resolution parameter for Leidenalg clustering.</dd>
<dt><strong><code>random_state</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The random state.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>labels</code></strong> :&ensp;<code>np.array
</code></dt>
<dd><span><span class="MathJax_Preview">[N, ]</span><script type="math/tex">[N, ]</script></span> The clustered labels.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def leidenalg_igraph(g, res, random_state=0):
    &#39;&#39;&#39;Leidenalg clustering on an igraph object.

    Parameters
    ----------
    g : igraph
        The igraph object of connectivities.
    res : float
        The resolution parameter for Leidenalg clustering.
    random_state : int, optional
        The random state.      

    Returns
    ----------
    labels : np.array     
        \([N, ]\) The clustered labels.
    &#39;&#39;&#39;
    partition_kwargs = {}
    partition_type = leidenalg.RBConfigurationVertexPartition
    partition_kwargs[&#34;resolution_parameter&#34;] = res
    partition_kwargs[&#34;seed&#34;] = random_state
    part = leidenalg.find_partition(
                    g, partition_type,
                    **partition_kwargs,
                )
    labels = np.array(part.membership)
    return labels</code></pre>
</details>
</dd>
<dt id="VITAE.utils.plot_clusters"><code class="name flex">
<span>def <span class="ident">plot_clusters</span></span>(<span>embed_z, labels, plot_labels=False, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the clustering results.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>embed_z</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, 2]</span><script type="math/tex">[N, 2]</script></span> The latent variables after dimension reduction.</dd>
<dt><strong><code>labels</code></strong> :&ensp;<code>np.array
</code></dt>
<dd><span><span class="MathJax_Preview">[N, ]</span><script type="math/tex">[N, ]</script></span> The clustered labels.</dd>
<dt><strong><code>plot_labels</code></strong> :&ensp;<code>boolean</code>, optional</dt>
<dd>Whether to plot text of labels or not.</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to save the figure.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_clusters(embed_z, labels, plot_labels=False, path=None):
    &#39;&#39;&#39;Plot the clustering results.

    Parameters
    ----------
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    labels : np.array     
        \([N, ]\) The clustered labels.
    plot_labels : boolean, optional
        Whether to plot text of labels or not.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;    
    n_labels = len(np.unique(labels))
    colors = [plt.cm.jet(float(i)/n_labels) for i in range(n_labels)]
    
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    for i,l in enumerate(np.unique(labels)):
        ax.scatter(*embed_z[labels==l].T,
                    c=[colors[i]], label=str(l),
                    s=16, alpha=0.4)
        if plot_labels:
            ax.text(np.mean(embed_z[labels==l,0]), np.mean(embed_z[labels==l,1]), str(l), fontsize=16)
    plt.setp(ax, xticks=[], yticks=[])
    box = ax.get_position()
    ax.set_position([box.x0, box.y0 + box.height * 0.1,
                        box.width, box.height * 0.9])
    ax.legend(loc=&#39;upper center&#39;, bbox_to_anchor=(0.5, -0.05),
        fancybox=True, shadow=True, markerscale=3, ncol=5)
    ax.set_title(&#39;Clustering&#39;)
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.plot()</code></pre>
</details>
</dd>
<dt id="VITAE.utils.plot_marker_gene"><code class="name flex">
<span>def <span class="ident">plot_marker_gene</span></span>(<span>expression, gene_name: str, embed_z, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the marker gene.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>expression</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, ]</span><script type="math/tex">[N, ]</script></span> The expression of the marker gene.</dd>
<dt><strong><code>gene_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The name of the marker gene.</dd>
<dt><strong><code>embed_z</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, 2]</span><script type="math/tex">[N, 2]</script></span> The latent variables after dimension reduction.</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to save the figure.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_marker_gene(expression, gene_name: str, embed_z, path=None):
    &#39;&#39;&#39;Plot the marker gene.

    Parameters
    ----------
    expression : np.array
        \([N, ]\) The expression of the marker gene.
    gene_name : str
        The name of the marker gene.
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;      
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    cmap = matplotlib.cm.get_cmap(&#39;Reds&#39;)
    sc = ax.scatter(*embed_z.T, c=&#39;yellow&#39;, s=15, alpha=0.1)
    sc = ax.scatter(*embed_z.T, cmap=cmap, c=expression, s=10, alpha=0.5)
    plt.colorbar(sc, ax=[ax], location=&#39;right&#39;)
    plt.setp(ax, xticks=[], yticks=[])
    ax.set_title(&#39;Normalized expression of {}&#39;.format(gene_name))
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.show()
    return None</code></pre>
</details>
</dd>
<dt id="VITAE.utils.plot_uncertainty"><code class="name flex">
<span>def <span class="ident">plot_uncertainty</span></span>(<span>uncertainty, embed_z, path=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Plot the uncertainty for all selected cells.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>uncertainty</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, ]</span><script type="math/tex">[N, ]</script></span> The uncertainty of the all cells.</dd>
<dt><strong><code>embed_z</code></strong> :&ensp;<code>np.array</code></dt>
<dd><span><span class="MathJax_Preview">[N, 2]</span><script type="math/tex">[N, 2]</script></span> The latent variables after dimension reduction.</dd>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path to save the figure.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def plot_uncertainty(uncertainty, embed_z, path=None):
    &#39;&#39;&#39;Plot the uncertainty for all selected cells.

    Parameters
    ----------
    uncertainty : np.array
        \([N, ]\) The uncertainty of the all cells.    
    embed_z : np.array
        \([N, 2]\) The latent variables after dimension reduction.
    path : str, optional
        The path to save the figure.
    &#39;&#39;&#39;          
    fig, ax = plt.subplots(1,1, figsize=(20, 10))
    cmap = matplotlib.cm.get_cmap(&#39;RdBu_r&#39;)
    sc = ax.scatter(*embed_z.T, cmap=cmap, c=uncertainty, s=10, alpha=1.0)
    plt.colorbar(sc, ax=[ax], location=&#39;right&#39;)
    plt.setp(ax, xticks=[], yticks=[])
    ax.set_title(&#34;Cells&#39; Uncertainty&#34;)
    if path is not None:
        plt.savefig(path, dpi=300)
    plt.show()
    return None</code></pre>
</details>
</dd>
<dt id="VITAE.utils.DE_test"><code class="name flex">
<span>def <span class="ident">DE_test</span></span>(<span>Y, X, gene_names, i_test, alpha: float = 0.05)</span>
</code></dt>
<dd>
<div class="desc"><p>Differential gene expression test.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>Y</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd><span><span class="MathJax_Preview">n,</span><script type="math/tex">n,</script></span> the expression matrix.</dd>
<dt><strong><code>X</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd><span><span class="MathJax_Preview">n,1+1+s</span><script type="math/tex">n,1+1+s</script></span> the constant term, the pseudotime and the covariates.</dd>
<dt><strong><code>gene_names</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd><span><span class="MathJax_Preview">n,</span><script type="math/tex">n,</script></span> the names of all genes.</dd>
<dt><strong><code>i_test</code></strong> :&ensp;<code>numpy.array</code></dt>
<dd>The indices of covariates to be tested.</dd>
<dt><strong><code>alpha</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The cutoff of p-values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>res_df</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>The test results of expressed genes with two columns,
the estimated coefficients and the adjusted p-values.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def DE_test(Y, X, gene_names, i_test, alpha: float = 0.05):
    &#39;&#39;&#39;Differential gene expression test.

    Parameters
    ----------
    Y : numpy.array
        \(n,\) the expression matrix.
    X : numpy.array
        \(n,1+1+s\) the constant term, the pseudotime and the covariates.
    gene_names : numpy.array
        \(n,\) the names of all genes.
    i_test : numpy.array
        The indices of covariates to be tested.
    alpha : float, optional
        The cutoff of p-values.

    Returns
    ----------
    res_df : pandas.DataFrame
        The test results of expressed genes with two columns,
        the estimated coefficients and the adjusted p-values.
    &#39;&#39;&#39;
    pinv_wexog, singular_values = _pinv_extended(X)
    normalized_cov = np.dot(
            pinv_wexog, np.transpose(pinv_wexog))
    h = np.diag(np.dot(X,
                    np.dot(normalized_cov,X.T)))

    def _DE_test(wendog,pinv_wexog,h):
        if np.any(np.isnan(wendog)):
            return np.empty(2)*np.nan
        else:
            beta = np.dot(pinv_wexog, wendog)
            resid = wendog - X @ beta
            cov = _cov_hc3(h, pinv_wexog, resid)
            t = np.array([])
            for j in i_test:
                if np.diag(cov)[j] == 0:
                    _t = float(&#34;nan&#34;)
                else:
                    _t = beta[j]/(np.sqrt(np.diag(cov)[j])+1e-6)
                t = np.append(t, _t)
            return np.r_[beta[i_test], t]

    res = np.apply_along_axis(lambda y: _DE_test(wendog=y, pinv_wexog=pinv_wexog, h=h),
                            0,
                            Y).T

    res_df = pd.DataFrame()
    for i,j in enumerate(i_test):
        if &#39;median_abs_deviation&#39; in dir(stats):
            sigma = stats.median_abs_deviation(res[:,len(i_test)+i], nan_policy=&#39;omit&#39;)
        else:
            sigma = stats.median_absolute_deviation(res[:,len(i_test)+i], nan_policy=&#39;omit&#39;)
        pdt_new_pval = np.array([stats.norm.sf(x)*2 for x in np.abs(res[:,len(i_test)+i]/sigma)])
        new_adj_pval = _p_adjust_bh(pdt_new_pval/len(i_test))
        _res_df = pd.DataFrame(np.c_[res[:,i], pdt_new_pval, new_adj_pval],
                        index=gene_names,
                        columns=[&#39;beta_{}&#39;.format(j),
                                 &#39;pvalue_{}&#39;.format(j),
                                 &#39;pvalue_adjusted_{}&#39;.format(j)])
        res_df = pd.concat([res_df, _res_df], axis=1)
    res_df = res_df[
        (np.sum(
            res_df[
                res_df.columns[
                    np.char.startswith(
                        np.array(res_df.columns, dtype=str),
                        &#39;pvalue_adjusted&#39;)]
            ] &lt; alpha, axis=1
        )&gt;0) &amp; np.any(~np.isnan(Y), axis=0)]
#     res_df = res_df.iloc[np.argsort(res_df.pvalue_adjusted).tolist(), :]
    return res_df</code></pre>
</details>
</dd>
<dt id="VITAE.utils.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>path, file_name, return_dict=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Load h5df data.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>path</code></strong> :&ensp;<code>str</code></dt>
<dd>The path of the h5 files.</dd>
<dt><strong><code>file_name</code></strong> :&ensp;<code>str</code></dt>
<dd>The dataset name.</dd>
</dl>
<h2 id="returns">Returns:</h2>
<p>data : dict
The dict containing count, grouping, etc. of the dataset.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(path, file_name,return_dict = False):
    &#39;&#39;&#39;Load h5df data.

    Parameters
    ----------
    path : str
        The path of the h5 files.
    file_name : str
        The dataset name.
    
    Returns:
    ----------
    data : dict
        The dict containing count, grouping, etc. of the dataset.
    &#39;&#39;&#39;     
    data = {}
    
    with h5py.File(os.path.join(path, file_name+&#39;.h5&#39;), &#39;r&#39;) as f:
        data[&#39;count&#39;] = np.array(f[&#39;count&#39;], dtype=np.float32)
        dd = anndata.AnnData(X=data[&#34;count&#34;])
        dd.layers[&#34;count&#34;] = data[&#34;count&#34;].copy()

        data[&#39;grouping&#39;] = np.array(f[&#39;grouping&#39;]).astype(str)
        dd.obs[&#34;grouping&#34;] = data[&#34;grouping&#34;]
        dd.obs[&#34;grouping&#34;] = dd.obs[&#34;grouping&#34;].astype(&#34;category&#34;)
        if &#39;gene_names&#39; in f:
            data[&#39;gene_names&#39;] = np.array(f[&#39;gene_names&#39;]).astype(str)
            dd.var.index = data[&#34;gene_names&#34;]
        else:
            data[&#39;gene_names&#39;] = None
        if &#39;cell_ids&#39; in f:
            data[&#39;cell_ids&#39;] = np.array(f[&#39;cell_ids&#39;]).astype(str)
            dd.obs.index = data[&#34;cell_ids&#34;]
        else:
            data[&#39;cell_ids&#39;] = None
        if &#39;days&#39; in f:
            data[&#39;days&#39;] = np.array(f[&#39;days&#39;]).astype(str)

        if &#39;milestone_network&#39; in f:
            if file_name in [&#39;linear&#39;,&#39;bifurcation&#39;,&#39;multifurcating&#39;,&#39;tree&#39;,
                               &#34;cycle_1&#34;, &#34;cycle_2&#34;, &#34;cycle_3&#34;,
                            &#34;linear_1&#34;, &#34;linear_2&#34;, &#34;linear_3&#34;, 
                            &#34;trifurcating_1&#34;, &#34;trifurcating_2&#34;, 
                            &#34;bifurcating_1&#34;, &#39;bifurcating_2&#39;, &#34;bifurcating_3&#34;, 
                            &#34;converging_1&#34;]:
                data[&#39;milestone_network&#39;] = pd.DataFrame(
                    np.array(np.array(list(f[&#39;milestone_network&#39;])).tolist(), dtype=str), 
                    columns=[&#39;from&#39;,&#39;to&#39;,&#39;w&#39;]
                ).astype({&#39;w&#39;:np.float32})
            else:
                data[&#39;milestone_network&#39;] = pd.DataFrame(
                    np.array(np.array(list(f[&#39;milestone_network&#39;])).tolist(), dtype=str), 
                    columns=[&#39;from&#39;,&#39;to&#39;]
                )
            data[&#39;root_milestone_id&#39;] = np.array(f[&#39;root_milestone_id&#39;]).astype(str)[0]            
        else:
            data[&#39;milestone_net&#39;] = None
            data[&#39;root_milestone_id&#39;] = None
            
        if file_name in [&#39;mouse_brain&#39;, &#39;mouse_brain_miller&#39;]:
            data[&#39;grouping&#39;] = np.array([&#39;%02d&#39;%int(i) for i in data[&#39;grouping&#39;]], dtype=object)
            data[&#39;root_milestone_id&#39;] = dict(zip([&#39;mouse_brain&#39;, &#39;mouse_brain_miller&#39;], [&#39;06&#39;, &#39;05&#39;]))[file_name]
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])).tolist(), dtype=np.float32)
        if file_name in [&#39;mouse_brain_merged&#39;]:
            data[&#39;grouping&#39;] = np.array(data[&#39;grouping&#39;], dtype=object)
            data[&#39;root_milestone_id&#39;] = np.array(f[&#39;root_milestone_id&#39;]).astype(str)[0]
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])).tolist(), dtype=np.float32)
        if file_name == &#39;dentate_withdays&#39;:
            data[&#39;covariates&#39;] = np.array([item.decode(&#39;utf-8&#39;).replace(&#39;*&#39;, &#39;&#39;) for item in f[&#39;days&#39;]], dtype=object)
            data[&#39;covariates&#39;] = data[&#39;covariates&#39;].astype(float).reshape(-1, 1)
        if file_name.startswith(&#39;human_hematopoiesis&#39;):
            data[&#39;covariates&#39;] = np.array(np.array(list(f[&#39;covariates&#39;])[0], dtype=str).tolist()).reshape((-1,1))
            
    data[&#39;type&#39;] = type_dict[file_name]
    if data[&#39;type&#39;]==&#39;non-UMI&#39;:
        scale_factor = np.sum(data[&#39;count&#39;],axis=1, keepdims=True)/1e6
        data[&#39;count&#39;] = data[&#39;count&#39;]/scale_factor

    if data.get(&#34;covariates&#34;) is not None:
        cov = data.get(&#34;covariates&#34;)
        cov_name = [&#34;covariate_&#34; + str(i) for i in range(cov.shape[1])]
        dd.obs[cov_name] = cov

    if return_dict:
        return data,dd
    else:
        return dd</code></pre>
</details>
</dd>
<dt id="VITAE.utils.compute_kernel"><code class="name flex">
<span>def <span class="ident">compute_kernel</span></span>(<span>x, y, kernel='rbf', **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes RBF kernel between x and y.</p>
<h2 id="parameters">Parameters</h2>
<pre><code>x: Tensor
    Tensor with shape [batch_size, z_dim]
y: Tensor
    Tensor with shape [batch_size, z_dim]
</code></pre>
<h2 id="returns">Returns</h2>
<pre><code>The computed RBF kernel between x and y
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_kernel(x, y, kernel=&#39;rbf&#39;, **kwargs):
    &#34;&#34;&#34;Computes RBF kernel between x and y.

    Parameters
    ----------
        x: Tensor
            Tensor with shape [batch_size, z_dim]
        y: Tensor
            Tensor with shape [batch_size, z_dim]

    Returns
    ----------
        The computed RBF kernel between x and y
    &#34;&#34;&#34;
    scales = kwargs.get(&#34;scales&#34;, [])
    if kernel == &#34;rbf&#34;:
        x_size = K.shape(x)[0]
        y_size = K.shape(y)[0]
        dim = K.shape(x)[1]
        tiled_x = K.tile(K.reshape(x, K.stack([x_size, 1, dim])), K.stack([1, y_size, 1]))
        tiled_y = K.tile(K.reshape(y, K.stack([1, y_size, dim])), K.stack([x_size, 1, 1]))
        return K.exp(-K.mean(K.square(tiled_x - tiled_y), axis=2) / K.cast(dim, tf.float32))
    elif kernel == &#39;raphy&#39;:
        scales = K.variable(value=np.asarray(scales))
        squared_dist = K.expand_dims(squared_distance(x, y), 0)
        scales = K.expand_dims(K.expand_dims(scales, -1), -1)
        weights = K.eval(K.shape(scales)[0])
        weights = K.variable(value=np.asarray(weights))
        weights = K.expand_dims(K.expand_dims(weights, -1), -1)
        return K.sum(weights * K.exp(-squared_dist / (K.pow(scales, 2))), 0)
    elif kernel == &#34;multi-scale-rbf&#34;:
        sigmas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 15, 20, 25, 30, 35, 100, 1e3, 1e4, 1e5, 1e6]

        beta = 1. / (2. * (K.expand_dims(sigmas, 1)))
        distances = squared_distance(x, y)
        s = K.dot(beta, K.reshape(distances, (1, -1)))

        return K.reshape(tf.reduce_sum(input_tensor=tf.exp(-s), axis=0), K.shape(distances)) / len(sigmas)</code></pre>
</details>
</dd>
<dt id="VITAE.utils.squared_distance"><code class="name flex">
<span>def <span class="ident">squared_distance</span></span>(<span>x, y)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the pairwise euclidean distance.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>Tensor with shape [batch_size, z_dim]</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>Tensor with shape [batch_size, z_dim]</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The pairwise euclidean distance between x and y.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def squared_distance(x, y):
    &#39;&#39;&#39;Compute the pairwise euclidean distance.

    Parameters
    ----------
    x: Tensor
        Tensor with shape [batch_size, z_dim]
    y: Tensor
        Tensor with shape [batch_size, z_dim]

    Returns
    ----------
    The pairwise euclidean distance between x and y.
    &#39;&#39;&#39;
    r = K.expand_dims(x, axis=1)
    return K.sum(K.square(r - y), axis=-1)</code></pre>
</details>
</dd>
<dt id="VITAE.utils.compute_mmd"><code class="name flex">
<span>def <span class="ident">compute_mmd</span></span>(<span>x, y, kernel, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>Computes Maximum Mean Discrepancy(MMD) between x and y.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>Tensor with shape [batch_size, z_dim]</dd>
<dt><strong><code>y</code></strong> :&ensp;<code>Tensor</code></dt>
<dd>Tensor with shape [batch_size, z_dim]</dd>
<dt><strong><code>kernel</code></strong> :&ensp;<code>str</code></dt>
<dd>The kernel type used in MMD. It can be 'rbf', 'multi-scale-rbf' or 'raphy'.</dd>
<dt><strong><code>**kwargs</code></strong> :&ensp;<code>dict</code></dt>
<dd>The parameters used in kernel function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>The computed MMD between x and y</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def compute_mmd(x, y, kernel, **kwargs):
    &#34;&#34;&#34;Computes Maximum Mean Discrepancy(MMD) between x and y.
    
    Parameters
    ----------
    x: Tensor
        Tensor with shape [batch_size, z_dim]
    y: Tensor
        Tensor with shape [batch_size, z_dim]
    kernel: str
        The kernel type used in MMD. It can be &#39;rbf&#39;, &#39;multi-scale-rbf&#39; or &#39;raphy&#39;.
    **kwargs: dict
        The parameters used in kernel function.
    
    Returns
    ----------
    The computed MMD between x and y
    &#34;&#34;&#34;
    x_kernel = compute_kernel(x, x, kernel=kernel, **kwargs)
    y_kernel = compute_kernel(y, y, kernel=kernel, **kwargs)
    xy_kernel = compute_kernel(x, y, kernel=kernel, **kwargs)
    return K.mean(x_kernel) + K.mean(y_kernel) - 2 * K.mean(xy_kernel)</code></pre>
</details>
</dd>
<dt id="VITAE.utils.sample_z"><code class="name flex">
<span>def <span class="ident">sample_z</span></span>(<span>args)</span>
</code></dt>
<dd>
<div class="desc"><p>Samples from standard Normal distribution with shape [size, z_dim] and
applies re-parametrization trick. It is actually sampling from latent
space distributions with N(mu, var) computed in <code>_encoder</code> function.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>args</code></strong> :&ensp;<code>list</code></dt>
<dd>List of [mu, log_var] computed in <code>_encoder</code> function.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The computed Tensor of samples with shape [size, z_dim].</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sample_z(args):
    &#34;&#34;&#34;Samples from standard Normal distribution with shape [size, z_dim] and
    applies re-parametrization trick. It is actually sampling from latent
    space distributions with N(mu, var) computed in `_encoder` function.
    
    Parameters
    ----------
    args: list
        List of [mu, log_var] computed in `_encoder` function.
        
    Returns
    ----------
    The computed Tensor of samples with shape [size, z_dim].
    &#34;&#34;&#34;
    mu, log_var = args
    batch_size = K.shape(mu)[0]
    z_dim = K.int_shape(mu)[1]
    eps = K.random_normal(shape=[batch_size, z_dim])
    return mu + K.exp(log_var / 2) * eps</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="VITAE.utils.Early_Stopping"><code class="flex name class">
<span>class <span class="ident">Early_Stopping</span></span>
<span>(</span><span>warmup=0, patience=10, tolerance=0.001, relative=False, is_minimize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>The early-stopping monitor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Early_Stopping():
    &#39;&#39;&#39;
    The early-stopping monitor.
    &#39;&#39;&#39;
    def __init__(self, warmup=0, patience=10, tolerance=1e-3, 
            relative=False, is_minimize=True):
        self.warmup = warmup
        self.patience = patience
        self.tolerance = tolerance
        self.is_minimize = is_minimize
        self.relative = relative

        self.step = -1
        self.best_step = -1
        self.best_metric = np.inf

        if not self.is_minimize:
            self.factor = -1.0
        else:
            self.factor = 1.0

    def __call__(self, metric):
        self.step += 1
        
        if self.step &lt; self.warmup:
            return False
        elif (self.best_metric==np.inf) or \
                (self.relative and (self.best_metric-metric)/self.best_metric &gt; self.tolerance) or \
                ((not self.relative) and self.factor*metric&lt;self.factor*self.best_metric-self.tolerance):
            self.best_metric = metric
            self.best_step = self.step
            return False
        elif self.step - self.best_step&gt;self.patience:
            print(&#39;Best Epoch: %d. Best Metric: %f.&#39;%(self.best_step, self.best_metric))
            return True
        else:
            return False</code></pre>
</details>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="VITAE" href="index.html">VITAE</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="VITAE.utils.reset_random_seeds" href="#VITAE.utils.reset_random_seeds">reset_random_seeds</a></code></li>
<li><code><a title="VITAE.utils.get_embedding" href="#VITAE.utils.get_embedding">get_embedding</a></code></li>
<li><code><a title="VITAE.utils.get_igraph" href="#VITAE.utils.get_igraph">get_igraph</a></code></li>
<li><code><a title="VITAE.utils.leidenalg_igraph" href="#VITAE.utils.leidenalg_igraph">leidenalg_igraph</a></code></li>
<li><code><a title="VITAE.utils.plot_clusters" href="#VITAE.utils.plot_clusters">plot_clusters</a></code></li>
<li><code><a title="VITAE.utils.plot_marker_gene" href="#VITAE.utils.plot_marker_gene">plot_marker_gene</a></code></li>
<li><code><a title="VITAE.utils.plot_uncertainty" href="#VITAE.utils.plot_uncertainty">plot_uncertainty</a></code></li>
<li><code><a title="VITAE.utils.DE_test" href="#VITAE.utils.DE_test">DE_test</a></code></li>
<li><code><a title="VITAE.utils.load_data" href="#VITAE.utils.load_data">load_data</a></code></li>
<li><code><a title="VITAE.utils.compute_kernel" href="#VITAE.utils.compute_kernel">compute_kernel</a></code></li>
<li><code><a title="VITAE.utils.squared_distance" href="#VITAE.utils.squared_distance">squared_distance</a></code></li>
<li><code><a title="VITAE.utils.compute_mmd" href="#VITAE.utils.compute_mmd">compute_mmd</a></code></li>
<li><code><a title="VITAE.utils.sample_z" href="#VITAE.utils.sample_z">sample_z</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="VITAE.utils.Early_Stopping" href="#VITAE.utils.Early_Stopping">Early_Stopping</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>